{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPpO1SKydXDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7b076d-0a7d-4193-eb4f-fcb9da90c7a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.1/708.1 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai-whisper gradio google-genai elevenlabs pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g685MjvZdYC0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import whisper\n",
        "import zipfile\n",
        "import gradio as gr\n",
        "from pathlib import Path\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import time\n",
        "import re\n",
        "import time\n",
        "from pydub import AudioSegment\n",
        "from elevenlabs import ElevenLabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koxEbVjhdbGE"
      },
      "outputs": [],
      "source": [
        "class WhisperSTT:\n",
        "    \"\"\"\n",
        "    Speech-to-Text using OpenAI Whisper for Arabic,\n",
        "    with optional Lebanese‐dialect correction via Google Gemini.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_size=\"medium\", gemini_api_key=None):\n",
        "        self.model = whisper.load_model(model_size)\n",
        "        self.model_size = model_size\n",
        "        self.gemini_api_key = gemini_api_key\n",
        "        self.gemini_client = None\n",
        "\n",
        "        if gemini_api_key:\n",
        "            try:\n",
        "                from google import genai\n",
        "                self.gemini_client = genai.Client(api_key=gemini_api_key)\n",
        "                print(\"Gemini text correction enabled\")\n",
        "            except ImportError:\n",
        "                print(\"Warning: google-generativeai package not installed. Using raw transcription.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Failed to initialize Gemini client: {str(e)}. Using raw transcription.\")\n",
        "\n",
        "    def transcribe(self, audio_path):\n",
        "        \"\"\"\n",
        "        Transcribe Arabic speech to text (language=\"ar\").\n",
        "        If Gemini is available, run correction on Lebanese dialect.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(audio_path):\n",
        "            raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
        "\n",
        "        # 1. Whisper transcription (Arabic)\n",
        "        result = self.model.transcribe(audio_path, language=\"ar\")\n",
        "        transcription = result[\"text\"]\n",
        "\n",
        "        # 2. If Gemini is set up, attempt text correction\n",
        "        if self.gemini_client and self.gemini_api_key:\n",
        "            try:\n",
        "                corrected = self._correct_text(transcription)\n",
        "                if corrected:\n",
        "                    return corrected\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Text correction failed: {str(e)}. Returning raw transcription.\")\n",
        "\n",
        "        return transcription\n",
        "\n",
        "    def _correct_text(self, text):\n",
        "        \"\"\"\n",
        "        Send a prompt to Gemini to correct Lebanese‐dialect text.\n",
        "        Only correct spelling/grammar; no additions.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            from google import genai\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            صحّح النص التالي المكتوب باللهجة اللبنانية:\n",
        "            - صحّح الأخطاء الإملائية والنحوية فقط.\n",
        "            - إذا كان في جملة استفهامية، ضيف علامة استفهام.\n",
        "            - ما تضيف ولا كلمة زيادة أو شرح.\n",
        "            - رجّع فقط النص المصحَّح، بدون علامات تنصيص أو أي إضافات.\n",
        "            النص: \"{text}\"\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.gemini_client.models.generate_content(\n",
        "                model=\"gemini-2.0-flash\", contents=prompt\n",
        "            )\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Text correction error: {str(e)}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmiK5IFLeEQs"
      },
      "outputs": [],
      "source": [
        "class MaguyGeminiLLM:\n",
        "    \"\"\"\n",
        "    Enhanced LLM implementation using your proven LangChain + Gemini pattern\n",
        "    Adapted for voice interaction with Maguy Abou Ghosn character\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key, knowledge_base_path=None):\n",
        "        \"\"\"\n",
        "        Initialize with knowledge base integration\n",
        "\n",
        "        Args:\n",
        "            api_key (str): Gemini API key\n",
        "            knowledge_base_path (str): Path to maguy_knowledge_base folder\n",
        "        \"\"\"\n",
        "        # Setup API key (same pattern as your chatbot)\n",
        "        if api_key is None:\n",
        "            try:\n",
        "                from google.colab import userdata\n",
        "                api_key = userdata.get('GEMINI_API_KEY')\n",
        "            except:\n",
        "                api_key = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "        if not api_key:\n",
        "            raise ValueError(\"GEMINI_API_KEY is required!\")\n",
        "\n",
        "        self.client = genai.Client(api_key=api_key)\n",
        "\n",
        "        # Load knowledge base\n",
        "        self.knowledge_base = self._load_knowledge_base(knowledge_base_path)\n",
        "\n",
        "        # Create system instruction with knowledge base\n",
        "        self.system_instruction = self._create_system_instruction()\n",
        "\n",
        "        # Initialize chat\n",
        "        self.chat = self._create_chat()\n",
        "\n",
        "        print(\" MaguyGeminiLLM with Knowledge Base initialized!\")\n",
        "\n",
        "    def _load_knowledge_base(self, kb_path=None):\n",
        "        \"\"\"\n",
        "        Load knowledge base files (adapted from your load_knowledge_base function)\n",
        "        \"\"\"\n",
        "        if kb_path is None:\n",
        "            kb_path = Path(\"maguy_knowledge_base\")\n",
        "        else:\n",
        "            kb_path = Path(kb_path)\n",
        "\n",
        "        if not kb_path.exists():\n",
        "            print(f\"Knowledge base path not found: {kb_path}\")\n",
        "            return \"\"\n",
        "\n",
        "        kb_content = \"\"\n",
        "        for file_path in kb_path.glob('*'):\n",
        "            if file_path.is_file():\n",
        "                try:\n",
        "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                        content = f.read()\n",
        "                        kb_content += f\"\\n\\n### {file_path.stem}\\n{content}\"\n",
        "                        print(f\"Loaded: {file_path.name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {file_path.name}: {e}\")\n",
        "        return kb_content\n",
        "\n",
        "    def _load_interview_style(self, interview_path=None):\n",
        "        \"\"\"\n",
        "        Load the annotated interview script for speaking style\n",
        "        \"\"\"\n",
        "        if interview_path is None:\n",
        "            possible_paths = [\n",
        "                \"interview_script.txt\",\n",
        "                \"maguy_interview.txt\",\n",
        "                \"speaking_style.txt\",\n",
        "                \"#ABtalks with Maguy Bou Ghosn - مع ماغي بو غصن.txt\"\n",
        "            ]\n",
        "            for path in possible_paths:\n",
        "                if Path(path).exists():\n",
        "                    interview_path = path\n",
        "                    break\n",
        "\n",
        "        if interview_path and Path(interview_path).exists():\n",
        "            try:\n",
        "                with open(interview_path, 'r', encoding='utf-8') as f:\n",
        "                    content = f.read()\n",
        "                    print(f\"Loaded interview style from: {interview_path}\")\n",
        "                    return content\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading interview style: {e}\")\n",
        "\n",
        "        print(\"Interview style file not found\")\n",
        "        return \"\"\n",
        "\n",
        "    def _create_system_instruction(self):\n",
        "        \"\"\"\n",
        "        Create comprehensive system instruction with knowledge base\n",
        "        \"\"\"\n",
        "        base_instruction = \"\"\"\n",
        "        إنتي ماغي بو غصن، الممثلة اللبنانية المشهورة. بتحكي باللهجة اللبنانية متل ما إنتي بتحكي بالحياة الحقيقية، مش بالفصحى أبداً.\n",
        "        قواعد مهمة للمحادثة:\n",
        "        1. اعتمدي على اللهجة اللبنانية 100% - لا تستعملي الفصحى أبداً\n",
        "        2. خلي إجاباتك قصيرة ومناسبة للمكالمة الصوتية (جملتين لتلت جمل بالكتير)\n",
        "        3. كوني طبيعية وودودة متل شخصيتك الحقيقية\n",
        "        4. إذا سألوك عن شي ما بتعرفيه، قولي \"ما بعرف\" بصراحة\n",
        "        5. استعملي التعابير اللبنانية الأصيلة والكلمات المحكية\n",
        "        6. المخاطب هو شاب، مش بنت، يعني قولي \"كيفك؟\" مش \"كيفِك؟\"، \"اشتقتلك\" مش \"اشتقتلِك\"، وهكذا.\n",
        "\n",
        "        أمثلة على إجاباتك:\n",
        "        - بدل \"كيف حالك؟\" → \"كيفك؟ شو أخبارك؟\"\n",
        "        - بدل \"أنا بخير\" → \"منيحة الحمد لله\"\n",
        "        - بدل \"شكراً لك\" → \"يسلموا إيديك\"\n",
        "        - بدل \"لا أعرف\" → \"ما بعرف والله\\\"\"\"\"\n",
        "\n",
        "        if self.knowledge_base:\n",
        "            base_instruction += f\"\\n\\nمعلومات مفصلة عنك:\\n{self.knowledge_base}\"\n",
        "        return base_instruction\n",
        "\n",
        "    def _create_chat(self):\n",
        "        return self.client.chats.create(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            config=types.GenerateContentConfig(\n",
        "                system_instruction=self.system_instruction,\n",
        "                temperature=0.7,\n",
        "                max_output_tokens=120,\n",
        "                top_p=0.9,\n",
        "                top_k=40\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def generate_response(self, user_input, temperature=0.7, max_tokens=120):\n",
        "        \"\"\"\n",
        "        Generate response (same interface as before)\n",
        "        \"\"\"\n",
        "        if not user_input or not user_input.strip():\n",
        "            return \"شو بدك تسألني؟\"\n",
        "\n",
        "        try:\n",
        "            response = self.chat.send_message(user_input)\n",
        "            response_text = response.text.strip()\n",
        "            return self._post_process_response(response_text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response: {str(e)}\")\n",
        "            return \"معليش، صار عندي مشكلة تقنية. جرب مرة تانية.\"\n",
        "\n",
        "    def _post_process_response(self, response):\n",
        "        \"\"\"\n",
        "        Enhanced post-processing for Lebanese dialect\n",
        "        \"\"\"\n",
        "        replacements = {\n",
        "            'أنا': 'انا',\n",
        "            'أنت': 'إنت',\n",
        "            'أنتِ': 'إنتي',\n",
        "            'هذا': 'هيدا',\n",
        "            'هذه': 'هيدي',\n",
        "            'ذلك': 'هيداك',\n",
        "            'تلك': 'هيديك',\n",
        "            'نعم': 'آه',\n",
        "            'لا': 'لأ',\n",
        "            'كيف حالك': 'كيفك',\n",
        "            'بخير': 'منيح',\n",
        "            'شكراً': 'يسلموا',\n",
        "            'من فضلك': 'لو سمحت',\n",
        "            'معذرة': 'معليش',\n",
        "            'طبعاً': 'أكيد',\n",
        "            'ممتاز': 'رائع',\n",
        "            'جميل': 'حلو',\n",
        "            'كثيراً': 'كتير',\n",
        "            'قليلاً': 'شوي',\n",
        "            'أريد': 'بدي',\n",
        "            'أحب': 'بحب'\n",
        "        }\n",
        "        for msa, leb in replacements.items():\n",
        "            response = response.replace(msa, leb)\n",
        "        # 3. Normalize all hamza-alef variants to plain alef\n",
        "        response = re.sub(r'[إأآ]', 'ا', response)\n",
        "\n",
        "        return response\n",
        "\n",
        "    def reset_conversation(self):\n",
        "        \"\"\"Reset conversation\"\"\"\n",
        "        self.chat = self._create_chat()\n",
        "        return \"مرحبا! انا ماغي بو غصن، شو بدك تحكيلي؟\"\n",
        "\n",
        "    def get_knowledge_summary(self):\n",
        "        \"\"\"Debug function to see what knowledge was loaded\"\"\"\n",
        "        return {\n",
        "            \"knowledge_base_size\": len(self.knowledge_base),\n",
        "            \"interview_style_size\": len(self.interview_style),\n",
        "            \"has_knowledge\": bool(self.knowledge_base),\n",
        "            \"has_interview\": bool(self.interview_style)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NplX9EkReJe5"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('maguy_knowledge_base.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('maguy_knowledge_base')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ElevenLabsTTS:\n",
        "    \"\"\"\n",
        "    High-fidelity ElevenLabs TTS wrapper, using the same settings\n",
        "    as the web UI for your custom Maguy voice.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        api_key: str,\n",
        "        voice_id: str,\n",
        "        output_dir: str = \"outputs\",\n",
        "    ):\n",
        "        if not api_key:\n",
        "            raise ValueError(\"ELEVENLABS_API_KEY is required\")\n",
        "        self.api_key = api_key\n",
        "        self.voice_id = voice_id\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        # Non-streaming endpoint for full quality\n",
        "        self.url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}\"\n",
        "\n",
        "        # These defaults are pulled from your voice definition:\n",
        "        self.settings = {\n",
        "            \"stability\": 1.0,\n",
        "            \"similarity_boost\": 1.0,\n",
        "            \"use_speaker_boost\": True,\n",
        "            \"style\": 0.0,\n",
        "            \"speed\": 0.90\n",
        "        }\n",
        "\n",
        "    def synthesize(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Send text to ElevenLabs, saving an MP3 with web-UI–matched settings.\n",
        "        \"\"\"\n",
        "        headers = {\n",
        "            \"xi-api-key\": self.api_key,\n",
        "            \"Content-Type\": \"application/json\",\n",
        "        }\n",
        "        payload = {\n",
        "            \"text\": text,\n",
        "            # model_id can remain default; web UI uses its own choice\n",
        "            \"voice_settings\": self.settings\n",
        "        }\n",
        "\n",
        "        resp = requests.post(self.url, json=payload, headers=headers, stream=True)\n",
        "        resp.raise_for_status()\n",
        "\n",
        "        filename = f\"tts_{int(time.time() * 1000)}.mp3\"\n",
        "        path = os.path.join(self.output_dir, filename)\n",
        "        with open(path, \"wb\") as f:\n",
        "            for chunk in resp.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        return path"
      ],
      "metadata": {
        "id": "F5OG5hRnw0GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgeby7iQeKqw",
        "outputId": "b5378335-63e1-4c94-8989-3b3933c72fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:12<00:00, 118MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini text correction enabled\n",
            " MaguyGeminiLLM with Knowledge Base initialized!\n"
          ]
        }
      ],
      "source": [
        "# API keys (or set via ENV / Colab userdata)\n",
        "GEMINI_API_KEY      = \"AIzaSyD1ZVmk2T_cOIZbkD7cJ5OwZEDieB_4_-g\"\n",
        "ELEVENLABS_API_KEY  = \"sk_4b6771baede8fc135e2cffb1f465eb633152b35fed0b29bd\"\n",
        "ELEVENLABS_VOICE_ID = \"vzCewNMrmxS35lNSDJ5T\"\n",
        "\n",
        "# Create Whisper STT (with Gemini correction)\n",
        "stt = WhisperSTT(model_size=\"medium\", gemini_api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Create Maguy Gemini LLM\n",
        "llm = MaguyGeminiLLM(\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    knowledge_base_path=\"maguy_knowledge_base\"\n",
        "    )\n",
        "\n",
        "tts = ElevenLabsTTS(api_key=ELEVENLABS_API_KEY, voice_id=ELEVENLABS_VOICE_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfTFaoqeeWtb"
      },
      "outputs": [],
      "source": [
        "def audio_chat(audio_path, chat_history):\n",
        "    \"\"\"\n",
        "    1. Transcribe user audio → text (Whisper+Gemini).\n",
        "    2. Generate Maguy’s text reply via Gemini LLM.\n",
        "    3. Synthesize reply via ElevenLabs REST API.\n",
        "    4. Append messages in OpenAI-chat format to history.\n",
        "    Returns: (history_messages, maguy_audio_path)\n",
        "    \"\"\"\n",
        "    print(\"▶️ audio_chat called\")\n",
        "    print(f\"    audio_path = {audio_path!r}\")\n",
        "\n",
        "    chat_history = chat_history or []\n",
        "\n",
        "    if audio_path is None:\n",
        "        print(\"    No audio received.\")\n",
        "        return chat_history, None\n",
        "\n",
        "    try:\n",
        "        # 1. Transcription\n",
        "        start = time.time()\n",
        "        user_text = stt.transcribe(audio_path)\n",
        "        end = time.time()\n",
        "        print(f\"    Transcription took {end-start:.1f}s, result={user_text!r}\")\n",
        "\n",
        "        # 2. Generate Maguy reply (text)\n",
        "        maguy_text = llm.generate_response(user_text)\n",
        "\n",
        "        # 3. Synthesize via ElevenLabs\n",
        "        maguy_audio_path = tts.synthesize(maguy_text)\n",
        "\n",
        "        # 4. Append to history in OpenAI format\n",
        "        chat_history.append({\"role\": \"user\", \"content\": user_text})\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": maguy_text})\n",
        "\n",
        "        return chat_history, maguy_audio_path\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"معليش، صار عندي مشكلة تقنية: {e}\"\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
        "        return chat_history, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "ojnyFFy1eYtB",
        "outputId": "36b3900f-c4fc-4df5-90c3-0694f4837f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://7dc23cbb76d12d8134.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7dc23cbb76d12d8134.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ audio_chat called\n",
            "    audio_path = '/tmp/gradio/67eef486da6c508c8f6bf427e21e542a022548552d465cc744a2405028d49e17/audio.wav'\n",
            "    Transcription took 5.1s, result='صباحو ماجي، كيفك اليوم؟'\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://7dc23cbb76d12d8134.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "with gr.Blocks(\n",
        "    title=\"Interactive Voice Call with Maguy Abou Ghosn\",\n",
        "    css=\"\"\"\n",
        "    /* 1. Import both Tajawal and Montserrat */\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Tajawal:wght@400;600&family=Montserrat:wght@500;700&display=swap');\n",
        "\n",
        "    /* 2. Define your gold & black palette */\n",
        "    :root {\n",
        "      --gold:  #D4AF37; /* classic metallic gold */\n",
        "      --black: #000000; /* deep black */\n",
        "      --white: #FFFFFF; /* for contrast */\n",
        "      --text:  #FFFFFF; /* white text for readability */\n",
        "    }\n",
        "\n",
        "    /* 3. Global body & text */\n",
        "    body {\n",
        "      background-color: var(--black);\n",
        "      color: var(--white);\n",
        "    }\n",
        "\n",
        "    /* 4. Remove default margins/padding on Gradio HTML wrappers */\n",
        "    div[class*=\"html\"] {\n",
        "      margin: 0 !important;\n",
        "      padding: 0 !important;\n",
        "    }\n",
        "\n",
        "    /* 5. Title & subtitle styling */\n",
        "    #title {\n",
        "      font-family: 'Montserrat', sans-serif !important;\n",
        "      font-weight: 700;\n",
        "      font-size: 2rem;\n",
        "      color: var(--gold);\n",
        "      margin: 0 !important;\n",
        "      padding: 0 !important;\n",
        "      text-align: center;\n",
        "    }\n",
        "    #subtitle {\n",
        "      font-family: 'Montserrat', sans-serif !important;\n",
        "      font-weight: 500;\n",
        "      font-size: 1rem;\n",
        "      color: var(--gold);\n",
        "      margin: 0 !important;\n",
        "      padding: 0 0 1em 0 !important;\n",
        "      text-align: center;\n",
        "    }\n",
        "\n",
        "    /* 6. Panels with subtle gold tint */\n",
        "    #left_col, #right_col {\n",
        "      background-color: rgba(212, 175, 55, 0.05);\n",
        "      border: 1px solid var(--gold);\n",
        "      border-radius: 12px;\n",
        "      padding: 15px;\n",
        "      box-shadow: 1px 1px 5px rgba(0,0,0,0.3);\n",
        "      margin-bottom: 0;\n",
        "    }\n",
        "\n",
        "    /* 7. Buttons in gold */\n",
        "    .gradio-container .gr-button {\n",
        "      background-color: var(--gold) !important;\n",
        "      color: var(--black) !important;\n",
        "      border-radius: 8px !important;\n",
        "      transition: filter .1s ease-in-out;\n",
        "    }\n",
        "    .gradio-container .gr-button:hover {\n",
        "      filter: brightness(1.1);\n",
        "    }\n",
        "\n",
        "    /* 8. Footer styling */\n",
        "    #footer {\n",
        "      text-align: center;\n",
        "      color: var(--gold);\n",
        "      font-family: 'Montserrat', sans-serif;\n",
        "      font-size: 1.25rem;\n",
        "      margin-top: 0;\n",
        "      padding-top: 5px;\n",
        "      border-top: 1px solid rgba(255,255,255,0.2);\n",
        "    }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "\n",
        "    # Header\n",
        "    gr.HTML(\"<h1 id='title'>🎤 Maguy Bou Ghosn Voice Chat</h1>\")\n",
        "    gr.HTML(\"<p id='subtitle'>Speak in Lebanese Arabic and hear Maguy reply like in a real phone call</p>\")\n",
        "\n",
        "    with gr.Group():\n",
        "        with gr.Row():\n",
        "            # Left side: voice interaction\n",
        "            with gr.Column(scale=1, elem_id=\"left_col\"):\n",
        "                audio_in = gr.Audio(\n",
        "                    label=\"🎙️ Record Your Voice\",\n",
        "                    sources=[\"microphone\", \"upload\"],\n",
        "                    type=\"filepath\"\n",
        "                )\n",
        "                submit_btn = gr.Button(\"Send to Maguy\")\n",
        "                audio_out = gr.Audio(\n",
        "                    label=\"🔊 Maguy's Voice Reply\",\n",
        "                    type=\"filepath\"\n",
        "                )\n",
        "\n",
        "            # Right side: chat history\n",
        "            with gr.Column(scale=2, elem_id=\"right_col\"):\n",
        "                chatbot = gr.Chatbot(\n",
        "                    label=\"💬 Chat History\",\n",
        "                    height=443,\n",
        "                    type=\"messages\"\n",
        "                )\n",
        "\n",
        "    # Footer\n",
        "    gr.HTML(\n",
        "        \"<div id='footer'>\"\n",
        "        \"Mohamad Ali Oussayli &nbsp;&amp;&nbsp; Maryam Saghir &nbsp;|&nbsp; Lebanese University\"\n",
        "        \"</div>\"\n",
        "    )\n",
        "\n",
        "    # Click = audio + response flow\n",
        "    submit_btn.click(\n",
        "        fn=audio_chat,\n",
        "        inputs=[audio_in, chatbot],\n",
        "        outputs=[chatbot, audio_out]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}